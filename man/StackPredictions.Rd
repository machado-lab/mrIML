% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/StackPredictions.R
\name{StackPredictions}
\alias{StackPredictions}
\title{Generate predictions for multiple outcomes using stacked multivariate learning}
\usage{
StackPredictions(yhats, data.test, covariance_mod = "gbm")
}
\arguments{
\item{yhats}{A \code{list} with one slot per binary outcome variable. Each outcome's slot
should be a \code{list} containing the following named items:
\itemize{
   \item \code{mod_1}: The full model object used to model the binary outcome variable
   \item \code{yhat}: Predictions from \code{mod_1} on the outcome (probability) scale
   \item \code{resid}: Residuals from \code{mod_1}. For binary outcomes,
   these residuals should be deviance residuals (see examples for how to calculate these)
   }}

\item{data.test}{A \code{dataframe} containing the testing split for cross-validation. This object
should have columns for all covariates that were used in the \code{mod_1}'s for generating 
out-of-sample predictions}

\item{covariance_mod}{A \code{character} string specifying which kind of algorithm to use for
learning the covariance matrix. Allowed options are currently 'gbm', 'gam' or 'lm'. Note that
for gbm models, \code{1000} regression trees will be stored for each outcome variable. Due to memory constraints, 
datasets with \code{>50} outcomes therefore cannot use gbm and will instead use a penalized gam by default}
}
\description{
This function fits separate penalized models to the residuals for each outcome variable 
to estimate parameters of complex multivariate variance covariance matrices. 
The initial predictions (supplied by the user) are then updated using the learned
covariance parameters.
}
\details{
Separate algorithms are fit to the residuals of each outcome, using the predictions
of the remaining outcomes (taken from the \code{yhat} slots in the list \code{yhats}) as covariates.
The ability to use complex interactions, such as can be learned in a \code{gbm} model, allows 
covariance matrices to be approximated and used to update existing out-of-sample predictions for 
each outcome. Crucially, this can be done without already knowing the out-of-sample 'truths' for 
each outcome variable, overcoming a major limitation of common joint species distribution models (where the other
species' out-of-sample occurrences must be known before generating predictions for the focal species)
}
\examples{
if(!require(MRFcov)){
devtools::install_github('nicholasjclark/MRFcov')}

# Load the MRFcov library to access the testing dataset
library(MRFcov)
data("Bird.parasites")

# A simple split of the data into training and testing subsets
train.dat <- Bird.parasites[1:350, ]
test.dat <- Bird.parasites[351:449, ]

# Run model 1 for each parasite; a simple logistic regression with a single covariate
# in this case but note that model 1 can be any model of the user's choice, 
# from simple regressions to complex hierarchical or deep learning models.

# Different structures can also be used for each species to handle mixed multivariate outcomes
yhats <- lapply(colnames(Bird.parasites)[1:4], function(species){

# Fit model one for each parasite; can easily modify this so that the user
# can specify the formula necessary for each species as a list of formulas

mod1 <- glm(formula(paste0(species,' ~ scale.prop.zos')), 
family = 'binomial', data = train.dat)

# Calculate probability predictions for the fitted training data
yhat <- predict(mod1, type = 'response')

# Calculate deviance residuals
# To calc residuals consistently for gbm or others for binomial models we need the formula
# train.dat[, species] equals binary observations; yhat equals model probability predictions
resid <- ifelse(train.dat[, species] == 1, 
sqrt((-2 * log(yhat))), 
-1 * (sqrt((-2*log(1 - yhat)))))
resid <- as.vector(resid)
#resid <- residuals(mod1, "deviance")
list(mod1 = mod1, yhat = yhat, resid = resid)
})

# A GAM example for the covariance matrix
gam_stack <- StackPredictions(yhats, data.test = test.dat, covariance_mod = 'gam')

# Calculate prediction accuracies for the stacked model and compare to the 
# simpler univariate model (i.e. model 1 only) for each species
lapply(seq(1, 4), function(species){
stacked_stats <- caret::confusionMatrix(factor(gam_stack$binary_preds[, species]), 
factor(as.matrix(test.dat)[, species]))
single_preds <- predict(yhats[[species]]$mod1, newdata = test.dat, type = 'response')
single_preds <- ifelse(single_preds > 0.4999, 1, 0)
single_stats <- caret::confusionMatrix(factor(single_preds), 
factor(as.matrix(test.dat)[, species]))
list(stacked_stats = round(stacked_stats$overall, 4),
single_stats = round(single_stats$overall, 4))
})

}
\references{
Xing, L, Lesperance, ML and Zhang, X (2020). Simultaneous prediction of multiple outcomes 
using revised stacking algorithms. Bioinformatics, 36, 65-72.
}
