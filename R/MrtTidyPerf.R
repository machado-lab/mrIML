#'mrIMLperformance :  Wrapper to calculate performance metrics (Mathews correlation coefficent, sensitivity
#'and specificity) for each model for each response variable. 
#'
#'@param yhats A \code{list} is the list generated by MrTidyPerf
#'@param model1 A \code{list}  #the model used to generate the yhats object 
#'@param X  A \code{dataframe} #is a response variable data set (specie, SNPs etc).
#'
#'@example
#'ModelPerf <- mrIMLperformance(yhats, model1, X=X) #ROC wont work for some reason. But MCC is useful (higher numbers = better fit)
#'ModelPerf 
#'
#'@details Outputs a dataframe of commonly used metric that can be used to compare model
#'performance of classification models.Performance metrics are based on testing data. 

mrIMLperformance <- function(yhats, model1, X){ #should be able to extract model info from yhats
  
  n_response<- length(yhats)
  mod_perf <- NULL

  
  yList <- yhats %>% purrr::map(pluck('yhatT')) #get the training yhats all together
    
    #modelperf <- map(seq(1,n_response), function(i){
  for( i in 1:n_response) {
      
    yd <- as.data.frame(yList[i])
    mathews <-  yardstick::mcc(yd,class, .pred_class) #yardstick is the tifymodels performance package.
    mathews <- mathews$.estimate #extract mcc
    sen <- yardstick::sens(yd,class, .pred_class)
    sen <- sen$.estimate
    spe <- yardstick::spec(yd,class, .pred_class)
    spe <- spe$.estimate
    #rocAUC <- yardstick::roc_auc(yhatT,class, .pred_class) #not working for some reason. Wants pred_class as numeric?

#add some identifiers
  mod_name <- class(model1)[1] #extracts model name
  #model1_perf <- c(mod_name, mathews, sen, spe)
  sp <- names(X[i])

#save all the metrics
  mod_perf[[i]] <- c( sp, mod_name, mathews, sen, spe)

  }
  
  mod1_perf<- do.call(rbind, mod_perf)
  mod1_perf <- as.data.frame( mod1_perf)
  colnames(mod1_perf) <- c('Species', 'Model_name', 'mcc', 'sensitivity', 'specificity')
  
  return ( mod1_perf)
}
